# Project Decisions Log
# WhatsApp Summarizer - I1 MVP

**Last Updated**: 2026-02-02
**Project Status**: Week 7 Phase 2 Complete (Real LLM Integrated) + Week 8 Planned (OpenAI Integration)

---

## ðŸ“‹ Decision Categories

1. [Architecture & Technology](#architecture--technology)
2. [Week 2 - Message Handling](#week-2---message-handling)
3. [Week 4 - Model Download](#week-4---model-download)
4. [Week 5 - AI Integration](#week-5---ai-integration)
5. [Week 8 - OpenAI API Integration](#week-8---openai-api-integration)
6. [Security & Privacy](#security--privacy)
7. [Performance & Optimization](#performance--optimization)
8. [Future Considerations](#future-considerations)

---

## Architecture & Technology

### AI Model Selection
**Decision**: TinyLlama 1.1B Q4_K_M (~700MB)
**Date**: 2026-01-31 (Week 0)
**Rationale**:
- Smaller than Phi-2 (700MB vs 1.8GB)
- Faster iteration during development
- Lower RAM requirements (4GB vs 6GB)
- Good enough for basic summarization
- Can upgrade to Phi-2 later if needed

**Alternatives Considered**:
- Phi-2 2.7B (rejected: too large for initial iteration)
- Gemma 2B (kept as option in model list)

---

### Minimum SDK Version
**Decision**: API 31 (Android 12)
**Date**: 2026-01-31 (Week 0)
**Rationale**:
- User requirement (explicit request)
- Simplifies notification listener permissions
- Reduces compatibility code
- Still covers ~70% of Android devices

**Alternatives Considered**:
- API 29 (Android 10) - rejected per user requirement
- API 33 (Android 13) - too restrictive

---

### Dependency Injection Framework
**Decision**: Hilt (over Koin)
**Date**: 2026-01-31 (Week 1)
**Rationale**:
- Official Google DI framework
- Better integration with Android components
- Compile-time validation
- Strong typing
- Better performance than reflection-based DI

**Alternatives Considered**:
- Koin (rejected: reflection-based, runtime errors)
- Manual DI (rejected: too much boilerplate)

---

### UI Framework
**Decision**: Jetpack Compose with Material 3
**Date**: 2026-01-31 (Week 1)
**Rationale**:
- Modern declarative UI
- Less boilerplate than XML
- Better state management
- Material 3 for latest design patterns
- Easier animations

**Alternatives Considered**:
- XML Views (rejected: outdated, more code)
- Flutter (rejected: not native Android)

---

### Database Encryption
**Decision**: SQLCipher with passphrase from Android ID
**Date**: 2026-01-31 (Week 1)
**Rationale**:
- Messages are sensitive personal data
- Encryption at rest is essential
- Android ID provides device-unique passphrase
- Transparent encryption (no code changes in DAOs)

**Known Issue**: SQLCipher 16KB page size warning (monitoring for updates)

---

### Preferences Storage
**Decision**: DataStore Preferences (over SharedPreferences)
**Date**: 2026-01-31 (Week 3)
**Rationale**:
- Type-safe API
- Coroutine-based (async by default)
- Safer than SharedPreferences
- Follows modern Android best practices
- Better error handling

**Alternatives Considered**:
- SharedPreferences (rejected: synchronous, not type-safe)
- EncryptedSharedPreferences only (rejected: for auth only)

---

## Week 2 - Message Handling

### Deleted Messages Display
**Decision**: Option C - Show deleted messages but exclude from summaries
**Date**: 2026-01-31 (Week 2)
**User Preference**: C (confirmed)
**Rationale**:
- Keep visible for context
- Users can see conversation flow
- Exclude from AI summaries (irrelevant content)
- Visual styling (red background, strikethrough)

**Alternatives Considered**:
- A: Keep visible and included in summaries (rejected: pollutes summaries)
- B: Hide completely (rejected: loses context)
- D: User preference toggle (rejected: adds complexity for I1)

---

### System Messages Display
**Decision**: Option C - Show system messages but exclude from summaries
**Date**: 2026-01-31 (Week 2)
**User Preference**: C (confirmed)
**Rationale**:
- Useful for context (who joined/left group)
- Not relevant for content summarization
- Visual styling (tertiary color container)

**Alternatives Considered**:
- A: Show and include in summaries (rejected: noise in summaries)
- B: Hide completely (rejected: loses group management context)
- D: Filter toggle (rejected: complexity)

---

### Media Message Display
**Decision**: Option A - Simple emoji indicators
**Date**: 2026-01-31 (Week 2)
**User Preference**: A (confirmed)
**Rationale**:
- Clean and simple for I1
- Low implementation complexity
- No additional storage for thumbnails
- Clear indication of message type

**Alternatives Considered**:
- B: Thumbnail placeholders (rejected: storage overhead)
- C: "View in WhatsApp" button (rejected: complexity)

---

### Database Migration Strategy
**Decision**: Option A for I1, Option C for production
**Date**: 2026-01-31 (Week 2)
**User Preference**: Aâ†’C (confirmed)
**Rationale**:
- Destructive migration acceptable for beta testing
- Simplifies development velocity
- Proper migrations before production release
- Beta testers will reinstall anyway

**Implementation**: Using `fallbackToDestructiveMigration()` for I1

---

### WhatsApp Business Testing Priority
**Decision**: Option B - Rely on user feedback during beta
**Date**: 2026-01-31 (Week 2)
**User Preference**: B (confirmed)
**Rationale**:
- Code already supports both packages
- Limited testing resources
- Beta testers will report if issues occur
- Can fix in Week 6 if needed

**Alternatives Considered**:
- A: Test in Week 3 (rejected: time constraint)
- C: Not a priority (kept as option)

---

### Message Parsing Error Recovery
**Decision**: Option A - Skip and log errors
**Date**: 2026-01-31 (Week 2)
**User Preference**: A (confirmed)
**Rationale**:
- Graceful degradation
- Doesn't block other messages
- Timber logs for debugging
- Can enhance later if users report issues

**Alternatives Considered**:
- B: Save raw data (rejected: storage overhead)
- C: Notify user (rejected: UX disruption)
- D: Fallback save unparsed (considered for later)

---

## Week 4 - Model Download

### Storage Location Selection
**Decision**: User picks storage location with visual space display
**Date**: 2026-01-31 (Week 4)
**User Preference**: User choice with visual feedback âœ…
**Rationale**:
- Users may have storage constraints
- Internal storage often limited
- External storage may be larger
- User sees available space before choosing
- Intelligent default (location with more space)

**Implementation**:
- StorageLocationScreen with real-time space display
- Visual usage bars (color-coded by usage %)
- Warning if <2GB available
- Prevents download if insufficient space (with 10% buffer)

---

### Download Network Policy
**Decision**: WiFi-only by default with user override toggle
**Date**: 2026-01-31 (Week 4)
**User Preference**: WiFi-only with override âœ…
**Rationale**:
- Models are large (700MB - 1.8GB)
- Prevents unexpected mobile data usage
- Users can override if needed
- Clear toggle in UI (WiFi chip)

**Implementation**:
- Default: `isWiFiOnlyDownload() = true`
- Toggle chip in ModelDownloadScreen header
- NetworkHelper for WiFi/mobile detection
- Clear error message if WiFi required

---

### Model Deletion Policy
**Decision**: Manual deletion only (user controls)
**Date**: 2026-01-31 (Week 4)
**User Preference**: Manual deletion âœ…
**Rationale**:
- Users may want to keep multiple models
- No storage pressure in I1
- User has full control
- Can add auto-delete later if needed

**Alternatives Considered**:
- B: Auto-delete when switching (rejected: user may want both)
- C: Keep multiple models (future enhancement)

---

### Week 4 Implementation Scope
**Decision**: Option A - Full implementation (OkHttp, progress, pause/resume)
**Date**: 2026-01-31 (Week 4)
**User Preference**: A, defer C to Week 5 âœ…
**Rationale**:
- Completeness over quick implementation
- Better UX with pause/resume
- Production-ready download system
- Can add background downloads (Option C) in Week 5 if time permits

**Implementation Features**:
- OkHttp with 30s timeouts
- HTTP Range headers for resume support
- Pause/resume/cancel operations
- MD5 checksum validation
- Progress tracking (throttled to 1% updates)
- StateFlow for reactive updates

---

### Pull-to-Refresh Implementation
**Decision**: Accompanist SwipeRefresh library
**Date**: 2026-01-31 (Week 3)
**Rationale**:
- Material3 PullToRefresh not yet available
- Accompanist is stable and well-maintained
- Easy to migrate later
- Works perfectly for I1

**Known Issue**: Deprecation warning (will migrate to Material3 when stable)

---

## Week 5 - AI Integration

### LLM Library Selection (Week 5)
**Initial Decision**: Llamatik (v0.14.0) - changed from kotlinllamacpp
**Date**: 2026-01-31 (Week 5)
**User Preference**: "Pick the most promising and popular/developed implementation, not niche wrapper"
**Initial Rationale**:
- Production-ready (apps on Google Play and App Store)
- More mature than kotlinllamacpp (which is alpha)
- Better documentation and examples
- Active development
- Support for latest llama.cpp features

**Initial Status**: âš ï¸ Library dependency not resolving from Maven Central
- Versions 0.13.0 and 0.14.0 mentioned in research did not exist
- Using StubAIEngine for mock responses
- Complete architecture ready, can swap implementation in 5 minutes

**Week 6 Investigation**: See "Week 6 - LLM Library Resolution" below for detailed findings

---

### Kotlin Version Upgrade
**Decision**: Upgrade to Kotlin 2.2.0 (from 1.9.22)
**Date**: 2026-01-31 (Week 5)
**Rationale**:
- Required for Llamatik compatibility
- Kotlin 2.0+ requires Compose compiler plugin
- Access to latest language features
- Better performance and compilation speed
- Required dependency chain upgrades (Room, Hilt, KSP)

**Cascading Upgrades**:
- Compose: Plugin-based (Kotlin 2.0+ requirement)
- KSP: 1.9.22-1.0.17 â†’ 2.2.0-2.0.2
- Hilt: 2.50 â†’ 2.57
- Room: 2.6.1 â†’ 2.8.4 (fixed KSP compatibility)
- Coroutines: 1.7.3 â†’ 1.9.0
- Serialization: 1.6.2 â†’ 1.7.3

---

### AI Architecture Pattern
**Decision**: Clean Architecture with AIEngine abstraction
**Date**: 2026-01-31 (Week 5)
**Rationale**:
- Library-agnostic interface (can swap implementations)
- Testable with StubAIEngine
- Domain-driven design (ActionItem, ParticipantHighlight)
- Separation of concerns (data layer â†” domain layer)
- Future-proof for library changes

**Components**:
- `AIEngine` interface (domain layer)
- `LlamatikEngine` implementation (data layer)
- `StubAIEngine` for testing (data layer)
- `GenerateSummaryUseCase` orchestration (domain layer)
- `AIModule` for DI binding (di layer)

---

### Prompt Engineering Approach
**Decision**: JSON schema-constrained generation with structured prompts
**Date**: 2026-01-31 (Week 5)
**Rationale**:
- Predictable output format
- Easy parsing (no regex or heuristics)
- Validates against schema
- Clear instructions for LLM
- Professional summary structure

**Schema Sections**:
1. overview (2-3 sentence summary)
2. keyTopics (array of topics)
3. actionItems (array with task, assignedTo, priority)
4. announcements (array of important items)
5. participantHighlights (array with participant, contribution)

---

### Testing Strategy During Library Block
**Decision**: Use StubAIEngine for UI/UX development
**Date**: 2026-01-31 (Week 5)
**Rationale**:
- Allows complete UI testing without real LLM
- Mock responses match expected schema
- 2s delay simulates inference time
- Can validate entire flow except actual inference
- Easy to swap for real engine (5 minute change in AIModule)

**Mock Behavior**:
- Returns realistic JSON summaries
- Simulates 2s inference delay
- Validates model loading
- Provides consistent test data

---

## Week 6 - LLM Library Resolution

### Comprehensive Library Investigation
**Decision**: Continue with StubAIEngine for I1 MVP, defer real LLM to Week 7+
**Date**: 2026-02-01 (Week 6)
**Rationale**:
- Extensive investigation revealed critical version mismatches between documentation and reality
- Both candidate libraries have API incompatibilities with their published versions
- StubAIEngine successfully validates complete app architecture and UI/UX
- Deferring real LLM unblocks I1 MVP beta distribution
- Architecture abstraction makes future library swap trivial (5 minutes)

**Investigation Summary**:

**Llamatik Investigation**:
- **Hypothesis**: Use Llamatik 0.14.0 (from research doc)
- **Finding**: Versions 0.13.0 and 0.14.0 **do not exist**
- **Latest Version**: 0.12.0 (confirmed via Maven Central and DEV.to article)
- **Status**: âœ… Dependency resolves successfully
- **Problem**: API incompatibility
  - Research doc shows `GenStream` interface - does not exist in 0.12.0
  - Research doc shows `LlamaBridge.generateStreamWithContext()` - different signature in 0.12.0
  - Limited documentation for actual 0.12.0 API
- **Conclusion**: Would require extensive reverse engineering to adapt

**kotlinllamacpp Investigation**:
- **Hypothesis**: Use kotlinllamacpp 0.2.0 (from research doc)
- **Finding**: Version 0.2.0 **does not exist**
- **Latest Version**: 0.1.2 (confirmed via Maven Central)
- **Status**: âœ… Dependency resolves successfully
- **Problem**: Complete API redesign
  - Research doc package: `io.github.ljcamargo.llamacpp`
  - Actual 0.1.2 package: `org.nehuatl.llamacpp`
  - Research doc: `LlamaHelper(contentResolver, scope, sharedFlow)`
  - Actual 0.1.2: Constructor parameters completely different
  - Research doc: `LlamaHelper.LLMEvent` sealed class
  - Actual 0.1.2: API structure entirely different
- **Conclusion**: Research doc based on unreleased/future version

**Root Cause Analysis**:
- Research document (WEEK5_LLAMACPP_RESEARCH.md) was based on GitHub repo code, not published artifacts
- Library maintainers may have refactored APIs between documentation and releases
- No way to use code examples without actual library version testing

**Decision Factors**:
1. **Time vs. Risk**: Reverse engineering either library would take 1-2 days with high uncertainty
2. **Architecture Success**: StubAIEngine proves architecture is sound and complete
3. **I1 MVP Scope**: Primary goal is validating message capture, UI/UX, and download system
4. **User Testing**: Beta testers can validate full app flow with mock summaries
5. **Clean Abstraction**: AIEngine interface means library swap later is trivial

**Next Steps (Post-I1)**:
1. **Week 7+**: Dedicated LLM integration sprint
2. Test actual published versions hands-on with physical device
3. Consider building custom JNI wrapper if both libraries remain problematic
4. Alternative: Wait for library authors to stabilize APIs (Llamatik/kotlinllamacpp both active)

---

## Week 7 - Real LLM Integration Success

### Llamatik 0.13.0 Integration
**Decision**: Integrate Llamatik 0.13.0 for real on-device LLM inference
**Date**: 2026-02-01 (Week 7)
**Status**: âœ… Compilation successful, awaiting physical device testing

**Discovery**:
- Week 6 tested Llamatik 0.12.0 which had incomplete API
- Llamatik 0.13.0 (released January 2026) has complete, functional API
- Week 6's finding that "0.13.0 does not exist" was incorrect - version released between Week 6 testing and Week 7

**API Verification** (via AAR extraction and source JAR inspection):
- âœ… `GenStream` interface present (was missing in 0.12.0)
- âœ… `initGenerateModel()`, `generate()`, `generateWithContext()`
- âœ… `generateJson()`, `generateJsonWithContext()` with schema support
- âœ… `generateStream()`, `generateStreamWithContext()` with callbacks
- âœ… `updateGenerateParams()` for temperature, tokens, top-p, top-k
- âœ… `nativeCancelGenerate()`, `shutdown()` for control and cleanup
- âœ… Native libraries for ARM64 (arm64-v8a) and x86_64

**Implementation**:
- Created `RealAIEngine.kt` implementing all AIEngine interface methods
- Updated `AIModule.kt` with 2-line swap (StubAIEngine â†’ RealAIEngine)
- Added dependency: `implementation("com.llamatik:library:0.13.0")`
- Build successful: APK size 87MB (+16MB for native libraries)

**Key Technical Details**:
- Parameter naming: Uses `contextBlock` (not `context`)
- Streaming: Implemented via `callbackFlow` with GenStream callbacks
- JSON generation: Uses temperature 0.1 for structured output
- Timeout: 120 seconds per generation
- Error handling: Comprehensive with AIEngineError types

**Decision Factors**:
1. **API Completeness**: All required methods present and documented
2. **Kotlin Native**: Direct Kotlin API, no Java interop needed
3. **Production Ready**: Active apps on app stores using Llamatik
4. **Native Support**: ARM64 libraries included for Android devices
5. **Maintenance**: Active development, recent releases

**Week 6 vs Week 7**:
- Week 6 (0.12.0): GenStream missing, API incomplete â†’ Deferred
- Week 7 (0.13.0): All APIs present, compilation successful â†’ Integrated

**Remaining Work**:
- Phase 3: Physical device testing (requires Android device)
- Phase 4: Edge case handling and performance optimization
- Phase 5: Documentation completion

**Result**: Week 5's architecture decision to use AIEngine abstraction enabled seamless library integration - exactly as designed.

---

### Domain Model Design
**Decision**: ActionItem and ParticipantHighlight as domain models (not entities)
**Date**: 2026-01-31 (Week 5)
**Rationale**:
- Clean separation: domain models â‰  database entities
- Reusable across layers
- Serializable for Room TypeConverters
- Part of public API (Summary domain model)
- Better for testing and mocking

**Implementation**:
- @Serializable annotation for JSON parsing
- Stored in SummaryEntity via TypeConverters
- Used in GenerateSummaryUseCase
- Displayed in SummaryDisplayScreen

---

## Security & Privacy

### PIN Storage
**Decision**: SHA-256 hash with UUID salt in EncryptedSharedPreferences
**Date**: 2026-01-31 (Week 1)
**Rationale**:
- Never store plaintext PIN
- Unique salt per device
- EncryptedSharedPreferences for additional layer
- Industry-standard hashing

---

### Message Storage Encryption
**Decision**: SQLCipher with Android ID passphrase
**Date**: 2026-01-31 (Week 1)
**Rationale**:
- Messages contain sensitive personal data
- Encryption at rest essential for privacy
- Android ID provides device-unique key
- Transparent to application code

---

### Notification Permission Explanation
**Decision**: Dedicated PermissionExplanationScreen before permission request
**Date**: 2026-01-31 (Week 3)
**Rationale**:
- Better permission grant rates
- Clear privacy assurances
- Explains exactly what we do with notifications
- Emphasizes local-only processing

---

## Performance & Optimization

### Download Progress Throttling
**Decision**: Update UI every 1% progress (not every byte)
**Date**: 2026-01-31 (Week 4)
**Rationale**:
- Reduces UI overhead significantly
- Smooth progress bar updates
- Minimal latency impact
- Efficient StateFlow updates

---

### Storage Space Buffer
**Decision**: Require 10% more space than model size
**Date**: 2026-01-31 (Week 4)
**Rationale**:
- Prevents "out of space" during download
- Accounts for temporary files
- Ensures safe download completion
- Industry best practice

---

### Database Version Management
**Decision**: Destructive migration for I1
**Date**: 2026-01-31 (Week 2, 3, 4)
**Rationale**:
- Faster development iteration
- Acceptable for beta testing
- Will implement proper migrations before production
- Current versions: 1 â†’ 2 â†’ 3

---

### Model Download Resume Strategy
**Decision**: HTTP Range headers + temp file
**Date**: 2026-01-31 (Week 4)
**Rationale**:
- Large files (700MB-1.8GB) prone to interruption
- Resume from where it left off
- Temp file becomes final file on completion
- Atomic operation (rename)

---

## Week 8 - OpenAI API Integration

### Add OpenAI as Alternative AI Provider
**Decision**: Add OpenAI API integration alongside local LLM
**Date**: 2026-02-02 (Week 8 Planning)
**Status**: ðŸ“‹ Planned (Post-I1 Enhancement)
**Documentation**: [WEEK8_OPENAI_PLAN.md](WEEK8_OPENAI_PLAN.md)

**Rationale**:
- **User Choice**: Let users choose between privacy (local) vs convenience (cloud)
- **Accessibility**: Users without high-end devices can use cloud API
- **Cost-Effective**: gpt-4o-mini costs ~$0.0006 per summary (affordable)
- **Quality**: OpenAI models may provide better summaries than TinyLlama
- **Flexibility**: Users can switch providers anytime
- **No Breaking Changes**: Existing local LLM remains default

**Implementation Strategy**:
1. Create `OpenAIEngine` implementing existing `AIEngine` interface
2. Use Retrofit + OkHttp for OpenAI API calls (already have OkHttp from Week 4)
3. Store API key in EncryptedSharedPreferences (already using for PIN)
4. Add `AIEngineProvider` wrapper for dynamic provider selection
5. Create Settings screen for provider switching
6. Update onboarding with provider selection option

**Model Selection**: gpt-4o-mini
- Input: $0.150 per 1M tokens
- Output: $0.600 per 1M tokens
- Context: 128k tokens
- Speed: Fastest OpenAI model
- Quality: Sufficient for WhatsApp summaries

**Security Considerations**:
- âœ… API key stored in EncryptedSharedPreferences (AES256-GCM)
- âœ… Clear privacy warnings for cloud processing
- âœ… Default to local provider (privacy-first)
- âš ï¸ Users must explicitly consent to send messages to OpenAI

**Alternatives Considered**:
- **gpt-4o**: Higher quality, 4x more expensive (rejected: unnecessary for summaries)
- **Anthropic Claude**: Alternative cloud provider (deferred: focus on one first)
- **Google Gemini**: Free tier available (deferred: privacy concerns with Google)
- **Local-only**: Keep only local LLM (rejected: limits accessibility)

**User Benefits**:
- Freedom to choose based on needs (privacy vs convenience vs cost)
- No storage needed for users without space for local models
- Faster summaries on low-end devices
- Always latest model version (no manual updates)

**Implementation Timeline**: 1-2 days
**Priority**: Medium (Post-I1, not critical for MVP)

---

## Future Considerations

### Items Deferred to Later Weeks

**Week 7+** (Post-I1 MVP):
- Real LLM library integration (requires hands-on testing with actual published versions)
- On-device inference testing with physical Android device
- Performance profiling with real models (memory, battery, inference speed)
- Library decision: Llamatik 0.12.0 vs kotlinllamacpp 0.1.2 vs custom JNI wrapper
- API adaptation for chosen library (reverse engineer actual API vs documentation)

**Week 5** (deferred - if time permits):
- Background downloads with WorkManager
- Additional model download sources
- Model signature verification
- Streaming summary generation UI

**Week 6**:
- Proper database migrations
- Performance profiling and optimization
- Accessibility improvements
- Dark mode verification
- Battery usage optimization

**Post-I1**:
- Multiple model storage
- Model delta updates
- Bandwidth throttling options
- Download queue management
- Summary history and caching
- Export summaries (PDF, text)

---

## Decision Making Process

### Criteria Used
1. **User Requirements**: Explicit user preferences take priority
2. **I1 Scope**: Simple, working features over complex, perfect ones
3. **Privacy First**: Always choose the more privacy-preserving option
4. **Development Velocity**: Fast iteration to meet 6-week timeline
5. **Future Flexibility**: Don't lock into irreversible decisions

### Stakeholders
- **Primary**: User (Mateusz)
- **Secondary**: Beta testers (5 parents)
- **Development**: Claude Code implementation

---

**Document Purpose**: Track all major decisions for future reference
**Revision Policy**: Update when significant decisions are made
**Review Schedule**: End of each week milestone
